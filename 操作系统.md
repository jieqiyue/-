- ​	进程、线程和协程区别
- 进程通信方式（管道，消息队列，共享内存，信号，信号量，socket）
- 进程调度算法（先来先服务，短作业优先，时间片轮换，多级反馈队列，优先级调度）
- 内存管理：分页（页面置换算法：手写 LRU）、分段、虚拟内存

### 硬件内存架构与Java内存模型

### 硬件内存架构

![img](https://img-blog.csdn.net/20170611211802727?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvamF2YXplamlhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

正如上图所示，经过简化CPU与内存操作的简易图，实际上没有这么简单，这里为了理解方便，我们省去了南北桥并将三级缓存统一为CPU缓存(有些CPU只有二级缓存，有些CPU有三级缓存)。就目前计算机而言，一般拥有多个CPU并且每个CPU可能存在多个核心，多核是指在一枚处理器(CPU)中集成两个或多个完整的计算引擎(内核),这样就可以支持多任务并行执行，从多线程的调度来说，每个线程都会映射到各个CPU核心中并行运行。在CPU内部有一组CPU寄存器，寄存器是cpu直接访问和处理的数据，是一个临时放数据的空间。一般CPU都会从内存取数据到寄存器，然后进行处理，但由于内存的处理速度远远低于CPU，导致CPU在处理指令时往往花费很多时间在等待内存做准备工作，于是在寄存器和主内存间添加了CPU缓存，CPU缓存比较小，但访问速度比主内存快得多，如果CPU总是操作主内存中的同一址地的数据，很容易影响CPU执行速度，此时CPU缓存就可以把从内存提取的数据暂时保存起来，如果寄存器要取内存中同一位置的数据，直接从缓存中提取，无需直接从主内存取。需要注意的是，寄存器并不每次数据都可以从缓存中取得数据，万一不是同一个内存地址中的数据，那寄存器还必须直接绕过缓存从内存中取数据。所以并不每次都得到缓存中取数据，这种现象有个专业的名称叫做缓存的命中率，从缓存中取就命中，不从缓存中取从内存中取，就没命中，可见缓存命中率的高低也会影响CPU执行性能，这就是CPU、缓存以及主内存间的简要交互过程，总而言之当一个CPU需要访问主存时，会先读取一部分主存数据到CPU缓存(当然如果CPU缓存中存在需要的数据就会直接从缓存获取)，进而在读取CPU缓存到寄存器，当CPU需要写数据到主存时，同样会先刷新寄存器中的数据到CPU缓存，然后再把数据刷新到主内存中。

### Java线程与硬件处理器

了解完硬件的内存架构后，接着了解JVM中线程的实现原理，理解线程的实现原理，有助于我们了解Java内存模型与硬件内存架构的关系，在Window系统和Linux系统上，Java线程的实现是基于一对一的线程模型，所谓的一对一模型，实际上就是通过语言级别层面程序去间接调用系统内核的线程模型，即我们在使用Java线程时，Java虚拟机内部是转而调用当前操作系统的内核线程来完成当前任务。这里需要了解一个术语，内核线程(Kernel-Level Thread，KLT)，它是由操作系统内核(Kernel)支持的线程，这种线程是由操作系统内核来完成线程切换，内核通过操作调度器进而对线程执行调度，并将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身,这也就是操作系统可以同时处理多任务的原因。由于我们编写的多线程程序属于语言层面的，程序一般不会直接去调用内核线程，取而代之的是一种轻量级的进程(Light Weight Process)，也是通常意义上的线程，由于每个轻量级进程都会映射到一个内核线程，因此我们可以通过轻量级进程调用内核线程，进而由操作系统内核将任务映射到各个处理器，这种轻量级进程与内核线程间1对1的关系就称为一对一的线程模型。如下图

![img](https://img-blog.csdn.net/20170608094427710?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvamF2YXplamlhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

如图所示，每个线程最终都会映射到CPU中进行处理，如果CPU存在多核，那么一个CPU将可以并行执行多个线程任务。



### 操作系统的启动

> cs寄存器和ip寄存器

CS是代码段寄存器，IP是指令指针寄存器（相当于偏移地址）。修改CS、IP的指令不同于修改通用的寄存器值的指令，修改通用寄存器的值可以用mov 指令（mav ax,123），mov指令被称为传送指令。修改CS、IP的指令是jmp指令。jmp指令被称为转移指令。那么，CPU执行哪条命令呢？就要从cs和ip寄存器计算得到的虚拟地址再转化为物理地址，CPU再去这个物理地址上取指令，再执行。

操作系统启动的时候就需要执行指令。那么起始的时候cs寄存器为0xFFFF0，ip=0x0000。那么再去检测键盘，显示器等。再去将磁盘的0磁道0扇区读入。这个扇区就是引导扇区。操作系统的所有东西就从这里开始。那么这个引导扇区的代码是什么呢？就是 一段汇编代码。

一共总的来说，启动的时候就是做了两件事情。将操作系统从硬盘上读入内存，再初始化一些数据结构，比如说GDT表，从实时模式到保护模式，IDT表，mem_map。给硬件创建数据结构。

### 操作系统接口

接口表现为函数调用。因为由操作系统提供，所以也可以叫系统调用。系统分为用户态和内核态。通过CPL(当前用户特权级),DPL（目标特权级）来进行判断。由于CS:IP是当前指令。所以用CS的最低两位来表示0表示内核态，3表示用户态，并且CPL也是这个值。只有当 CPL 为0时才可以访问内核态。**这个是由硬件来进行检测的。**  系统上面说过初始化的时候会有GDT表项，GDT存了某一个内存是0，还是3。那要是非得进入内核呢？这个提供了唯一的方法，就是通过中断进入内核。通过int 0x80 来做一个中断，并且将中断号4置入eax。通过这个eax的值，系统能够知道到底要采取什么措施来进行处理。

上层应用通过系统接口来进入内核态。是通过什么手段来阻止进入内核态的？

通过硬件检查指令执行时的CPL和DPL来判断是否有权限去执行。

### 操作系统出现

原先是批处理，就是一个任务接着一个任务的执行，前面一个任务没有执行完毕后面一个任务是不能够继续执行的。那么当后期计算机被应用于多个领域了之后，各种任务类型都有，比如说IO的任务，计算的任务，那么此时就需要在IO等待的时候切换到另外一个任务去执行，这样的话原先的简单的批处理显然就不能实现了。此时就需要操作系统来进行任务的调度。

### 内核设计的两种模式

- 微内核

  它提倡内核功能尽可能少：仅仅只有进程调度、处理中断、内存空间映射、进程间通信等功能。而开发者们把实际的进程管理、内存管理、设备管理、文件管理等服务功能，做成一个个服务进程。微内核有很多优点，首先，系统结构相当清晰利于协作开发。其次，系统有良好的移植性，微内核代码量非常少，就算重写整个内核也不是难事。最后，微内核有相当好的伸缩性、扩展性，因为那些系统功能只是一个进程，可以随时拿掉一个服务进程以减少系统功能，或者增加几个服务进程以增强系统功能。但是微内核的缺点是内核性能不够，多模块之间调用，并且交由进程进行实际功能的实现，这样的话还增加了进程切换的开销。

- 宏内核


### 多进程图像

多进程是为了充分利用CPU，符合多道程序设计而出现的一个概念。进程用PCB来表示，并且有各个不同的状态，这些状态对应这进程的生命周期。并且各个状态之间可以相互转换。在进行CPU执行权的转换的时候有各种调度算法等。并且有些状态是不能够占用CPU的。只有运行态才能够占用CPU。并且通过队列来保存进程。

多进程怎样推进呢？用pcb放在不同的队列中，并且用状态来推进转化。

怎样切换进程呢？就是通过进程调度算法。然后将CPU中寄存器的信息给保存在pcb中。就是保存现场。并且将新的现场的pcb的值赋值给CPU中的寄存器。这个代码是用汇编写的。

这种多进程程序带来了一些好处，势必会带来一些需要解决的问题。

> 多进程是如何组织的？

状态和队列

> 操作系统是怎样切换各个进程的?

​	切换分为两个部分。执行指令的切换和映射表的切换。同样的，也可以分为线程的切换和进程的切换。进程切	换需要切换指令执行位置，即各个寄存器的值等。而线程的切换相对来说更加的轻量级。只需要切换指令的执	行位置。而内存映射表是不用切换的。

​	线程之间虽然有共享的数据，但是也有不共享的数据。线程之间栈是不共享的。

- 线程切换过程

  

> 操作系统是怎样让各个进程地址分开的？

> 操作系统同步

​	进程间可以同时操作同一个变量吗？线程间因为共用了同一个地址空间，所以全局变量可以被同时访问到。所	以可以同时操作同一个变量，而进程间呢？

### 中断和异常的处理机制，系统调用

在发生中断的时候，不仅仅就是根据中断号跳转到处理例程去处理这么简单。还需要有保存恢复机制。那么要实现这个机制，还需要通过硬件和软件相互配合来实现。

> 中断

​	对于硬件：设置中断标记，CPU发现标记后，产生中断号，然后发给操作系统。那么操作系统可以找到对应的处	理例程。

​	对于软件：OS保存当前处理状态。保存现场。清除中断标记。

> 异常

![image-20210602114436499.png](https://i.loli.net/2021/06/02/8sNAz5dlISG69YM.png)

对于异常处理来说，OS可能有两种处理，有可能是因为OS提供的资源没有到位，那么，OS会在资源提供到位之后，重新执行这条指令。那么，也有可能直接杀死这个程序。

> 系统调用

​	应用程序需要OS提供的一些服务，那么就要调用系统调用。

### 内存分配算法

#### 连续内存

- 首次适配

  需要按照地址排序空闲列表。然后找一个能够满足要分配的大小的那个内存块就分配。

  优势：简单。易于产生更大的空闲块。

  劣势：外碎片多，不确定

- 最优适配

  找到一块最贴近要分配大小的内存块。

- 最差适配

  如果后期要分配一个大内存，那么可能就找不到了。因为在前面是优先拆分大空闲块的，那么大的都被拆分完了，那么在后面可能就找不到了。
  
- 最佳适配

  最佳适配算法是最容易产生外碎片的了。

那么这些都是简单的一些算法。实际的操作系统会采取更加复杂的方法来分配内存。而且，上面的方法都有外碎片或者内碎片的问题。那么，还需要一些内存整理的算法。

> 交换式碎片整理

​	将硬盘利用起来，在内存不够的时候将内存中的程序给交换到硬盘上面。 

> 压缩式碎片整理

​	调整程序在内存中的位置。可以通过软件或者硬件来实现重定位。

#### 非连续内存

https://www.cnblogs.com/alantu2018/p/9002309.html

分段。分页，多级页表，反向页表。这里的页表存放在mmu中。TLB缓存近期访问的页帧转换表项。

反向页表的设计初衷是说：将页寄存器的大小与程序的逻辑地址大小无关。一般是通过逻辑地址找到页帧号。而反向页表的设计理念是通过页帧号找到逻辑页号。那么难点就是如何实现这种反向查找。这种发式的优点有很多。比如说占用空间少。那么设计方案有：1. 关联存储器。但是这种代价太大。难以在单个周期内完成。2. 基于hash计算。

### 虚拟内存

起因：应用程序所需要的内存的增长速率大于硬件内存的增长速率。

以下两种技术的比较：

![image-20210607165350063](C:/Users/Jieqiyue/AppData/Roaming/Typora/typora-user-images/image-20210607165350063.png)

> 覆盖技术

   将相互之间没有调用关系的模块可以共用同一块内存。那么这种特别麻烦。

> 交换技术

交换是存在与不同程序之间的。粒度会比较大。通常将现在不执行的程序换出。

### 虚存技术

![](https://i.loli.net/2021/06/07/gt2yFWNAO5BHnbQ.png)

虚拟内存就是不把数据和代码一起全部放到内存中去。而是放一部分。那么要是要去访问那些没有在内存中的数据的时候，就会出现缺页异常。发生缺页异常也会有两种情况。在缺页的时候就需要将硬盘上面的数据放入内存中。那么内存此时可能满了，也可能没有满。

那么缺页是怎么判断的呢？就是通过页表项中的一些bit位进行的。可能其中一位是0代表没有在内存中，那么就需要进行页面换入（还有空闲内存）或者是页面置换（没有空闲内存，用相应的置换算法，比如说lru）来将这个页让它在内存中存在。这样的话，内存中最终有这个页了，那么重新执行那句引发缺页异常的指令就可以正常执行了。

很重要，下面！！！

![image-20210607173202248](C:/Users/Jieqiyue/AppData/Roaming/Typora/typora-user-images/image-20210607173202248.png)

这幅图就是说基于页式内存管理之下，虚存要怎么实现。

可以知道，在之前从逻辑地址到物理地址的映射关系，我们使用分页手段来实现。那么就有页表项，页表项的值可能就是物理页帧。那么页表项也不仅仅只是一个页帧号。可能还有一些其它位，这些其它位也蕴含了不同的含义与作用。比如说那个访问位，当选择最近最少使用算法进行选择一个页换出的时候，就需要去判断这个位是否置位为1。如果为1，代表最近被访问过，那么就不会将这个页给换出。那么在硬盘上存放的数据也是有多种新式的，比如说代码或者是某一个数据。

> 页面置换算法



- ![image-20210607190810086](C:/Users/Jieqiyue/AppData/Roaming/Typora/typora-user-images/image-20210607190810086.png)

  一般这种算法实现不了。因为需要知道未来的情况。

- FIFO

  将驻留时间最长的页面给置换出去。

- LRU

  将最久没有被使用的页面给置换出去。
  
- 时钟页面置换算法

  前面的lru算法要维护访问的顺序，就是把最近访问过的页面放在比较前面的位置上。那么要维护这种是比较难的。所以出现了这种时钟clock页面置换算法。

  那么这种算法利用到了页表项中的某一位bit来做的。当CPU访问了某一页的话，那么就把这个位置位1。那么，如果这个位为1那么就粗略的认为这个页面最近被访问过。那么不停的轮询（扫描）整个页表，当发现这个bit位0就认为这个页有段时间没有访问了，就可以直接把这个页给换出了。

- 二次机会法

  这个算法是对上面那个算法的一种改进。上面的算法是只是使用一个位来进行判断是否换出。而这种二次机会法却要使用到两个位来进行判断。只有当访问位为0，而且dirty bit 也为0的时候才会被换出。这样的话，如果一个页被写了那么，可以认为这个页在最近还是有可能会被写入，那么就先不把这个页给置换出去。

- 最不常用算法 (LFU)

  对于每一个页都有一个访问计数器。那么在每次要置换页的时候，就选择一个访问次数最小的进行替换。这个LFU是根据frequency频率来进行排序，而上面那个lru是recently是时间来进行排序。

belady现象就是，分配更多的页帧（物理资源）但是缺页中断的次数并没有因此而减少。这种现象出现在FIFO算法中。但是LFU,二次机会法，时钟页面置换算法等都不会出现这个问题。

以上就是所有的页面置换算法。

**可以看出来，FIFO算法是一种最简单的算法。先进先出，它并没有考虑页面的访问之类的。而LRU就会考虑。在经常访问的页面就会被提到前面。而置换的时候是去尾部选择一个页进行置换的。所以LRU会更好一些。然后，LRU的开销会很大。因为要维护访问顺序。所以，时钟页面置换算法就是对LRU的一个改进。它没有精确的维护一个LRU访问次序的链表，而是简单的用了页表中的一个访问位来进行判断。这样就大大的减少了维护访问顺序的开销。虽然是不精确的维护。然后二次机会法又是对前面这个时钟置换算法的一种改进，用了两个位来进行判断。那么，通过以上各种算法，我们也可以知道，光光有一个算法并不是万能的。如果能够写出具有很好的时间局部性，和空间局部性的程序，那么配合上算法，就能够很好的提高程序运行的性能。**

以上都是 局部的页面置换算法，接下来看两个全局页置换算法。

- 工作集置换算法

  在这种算法中有一个当前时间，有一个窗口大小。那么工作集就是当前时间之前，往前推1个滑动窗口那么大。那么在这个窗口中出现的页面会被留下，当时间往后走，当有页面已经出了这个滑动窗口了，那么就之间删掉。与之前不同的是，不一定要等到物理页帧都满了才会去删。这个是只要出了滑动窗口就去删。那么这种是对于全局来说的。我们还可以引入缺页率来进行动态的调整这个工作集的大小。当缺页率高的时候，可以增加物理页帧的分配。反之。因为一般来说，物理页帧越多，那么缺页率越低。

### 进程

进程包括很多个部分。![image-20210608170759161](C:/Users/Jieqiyue/AppData/Roaming/Typora/typora-user-images/image-20210608170759161.png)

 	

进程的特点：

1. 动态性
2. 并发性，并行性（多CPU才能实现）
3. 独立性（各个进程在运行之间正确性互不影响，独立的地址空间）
4. 制约性（各个进程会竞争资源，并且还有各个进程的调度）

那么 程序（OS） = 算法 + 数据结构（PCB）

> PCB 是什么

![image-20210608171646457](../../TyporaImages/image-20210608171646457.png)

![image-20210608171747606](../../TyporaImages/image-20210608171747606.png)

pcb的组织方式：

链表的方式。当然这个也是和程序的特点相结合的。因为进程总是会创建和销毁，那么就要求pcb要经常的删除和插入。那么链表显然是更加的适合这种情况。

> 进程的状态

![image-20210608183410359](../../TyporaImages/image-20210608183410359.png)

![image-20210608183912617](../../TyporaImages/image-20210608183912617.png)

![image-20210608184304408](../../TyporaImages/image-20210608184304408.png)

#### 进程的创建

进程创建时操作系统提供给用户的一个接口。比如说在Linux中可以用fork系统调用创建进程。那么新创建的进程是对原来的进程的一个完全的复制（除了pid不一样）。但是fork的返回值是不一样的。所以可以通过返回值来进行判断是否是子进程。子进程在fork（）的时候得到的返回值是0。子进程并不会去执行这个fork（）。类似的代码如下

```c
main{
	int childPID;
    childPID = fork();
    if (childPID == 0){
        // 子进程进入到这里
        exec("new",arg1,arg2...);// 子进程载入
    }else{
        // 父进程进入到这里
    }
}
```

#### 进程调度算法

- 轮询算法

  根据时间片，如果时间片用完了就换一个进程执行。这个算法需要设置好时间片的大小。时间片设置的太小的话会频繁的切换进程造成开销增大。一般来说需要控制在切换时间占用所有时间的百分之一。如果设置的太大的话，那么这个算法就退化成了FCFS算法了。这种算法好处就是能够得到公平性不会造成线程饥饿的现象。

- 先来先服务

  这种算法的平均等待时间取决于线程来的顺序。如果是按照顺序从小到大来的话，那么这个算法是和那个sjf算法一样的。当然也有最差情况。

- 多级反馈队列

  以上的算法都是单一的一种算法。但是各种进程的优先级不同。那么根据优先级的不同将进程放入不同的队列里面，并且各种队列里面用不同的调度策略。比如说优先级高的进程用轮询算法。而低优先级的用fcfs算法。并且能够根据反馈调整进程所在的队列。比如说进程等待的越久就把进程的优先级提高。

- 短任务优先

各种调度算法都必须要考虑几个方面的问题，并且这些方面不能够完全的满足，只能是做一些取舍。

- 公平性
- CPU使用率
- 周转时间
- 等待时间

#### 进程的退出

进程在创建的时候就会分配资源。比如pcb，pcb是在用户空间的。那么在进程退出的时候，其实进程自己是不能够去回收自己的pcb的，那么此时就需要父进程来帮助回收pcb（父进程调用wait（）系统调用）。那么，在用户空间中将进程的信息给清除了之后，这个进程的状态就是僵尸状态，比如说调用了exit（）调用。就会转化为僵尸状态。如果父进程先于子进程退出了，那么此时就需要root进程来定期的扫描进程的队列去找到僵尸状态的进程，定期的做一些回收操作。

### 线程

![image-20210608185132996](../../TyporaImages/image-20210608185132996.png)

  那么可以看到，各个线程有不同的控制流。线程之间有独立的比如说寄存器，pc，sp，state等。但是共用了进程的data，file，heap，code等。所以，可以看出来，进程只是给线程提供了线程执行所必要的资源。而真正执行代码的是线程。

![image-20210608190058344](../../TyporaImages/image-20210608190058344.png)

#### 线程的分类

![image-20210608190253877](../../TyporaImages/image-20210608190253877.png)

![image-20210608190438441](../../TyporaImages/image-20210608190438441.png)

用户级线程是用线程库来实现的。对于OS来说，OS不能够感知到用户级线程的存在只能够感知到这些用户级线程对应的那个进程。那么这样的话有一些好处和坏处。那么这些不同的线程实现方式是由不同的操作系统来实现的。现在的Windows和Linux支持内核级线程。

#### 上下文切换

![image-20210608192347401](../../TyporaImages/image-20210608192347401.png)

### 线程间同步

> 怎样保证线程安全？

一般来说一条编程语句可能会对应于几条机器指令，而且这几条机器指令是不符合原子性的，这样的话，再加上调度策略那么很可能就出现线程不安全的问题。并且问题难以复现。那么最直观的方法可以加锁。那么将一个操作

> 怎样设计来保证临界区的安全性？

- 第一种方法：屏蔽硬件中断

  就是把中断给禁用掉。因为线程安全的问题就是在多线程并发的环境下发生的，多个线程可以被调度器调度，并且执行顺序不是理想顺序，那么当我们一个线程要进入临界区的时候就把中断给禁用了。那么此时就不会进行进程调度了。就等于说在恢复中断之前就一定不会打断这个线程。

  那么也有局限性。比如说性能降低，不能响应中断，那么外设的中断也不能响应了。

- 第二种方法：基于软件的方法

- 第三种方法：更高级的抽象

  利用硬件的原子操作。

  $x^4$  

  