### RabbitMQ

生产者端的配置

```yaml
server:
  port: 8021
spring:
  #给项目来个名字
  application:
    name: rabbitmq-provider
  #配置rabbitMq 服务器
  rabbitmq:
    host: 159.75.140.136
    port: 5672
    username: user
    password: mysqlinsert
#    虚拟host 可以不设置,使用server默认host
#    virtual-host: JCcccHost
    #消息确认配置项

    #确认消息已发送到交换机(Exchange)
    publisher-confirm-type: correlated
    #确认消息已发送到队列(Queue)
    publisher-returns: true
```

消费者端的配置

```yaml
server:
  port: 8022
spring:
  #给项目来个名字
  application:
    name: rabbitmq-consumer
  #配置rabbitMq 服务器
  rabbitmq:
    host: 159.75.140.136
    port: 5672
    username: user
    password: mysqlinsert

    listener:  #加了2下面2个属性,消费消息的时候,就必须发送ack确认,不然消息永远还在队列中
      direct:
        acknowledge-mode: manual
      simple:
        acknowledge-mode: manual
```

消息推送端的config.java  的配置

```java 
@Configuration
public class RabbitConfig {

    @Bean
    public RabbitTemplate createRabbitTemplate(ConnectionFactory connectionFactory) {
        RabbitTemplate rabbitTemplate = new RabbitTemplate();
        rabbitTemplate.setConnectionFactory(connectionFactory);
        //设置开启Mandatory,才能触发回调函数,无论消息推送结果怎么样都强制调用回调函数
        rabbitTemplate.setMandatory(true);

        rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {
            @Override
            public void confirm(CorrelationData correlationData, boolean ack, String cause) {
                System.out.println("ConfirmCallback:     " + "相关数据：" + correlationData);
                System.out.println("ConfirmCallback:     " + "确认情况：" + ack);
                System.out.println("ConfirmCallback:     " + "原因：" + cause);
            }
        });

        rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() {
            @Override
            public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) {
                System.out.println("ReturnCallback:     " + "消息：" + message);
                System.out.println("ReturnCallback:     " + "回应码：" + replyCode);
                System.out.println("ReturnCallback:     " + "回应信息：" + replyText);
                System.out.println("ReturnCallback:     " + "交换机：" + exchange);
                System.out.println("ReturnCallback:     " + "路由键：" + routingKey);
            }
        });

        return rabbitTemplate;
    }

}
```

上面这段代码，解释就是在下面这里，上面配置的这两个函数的作用，以及会在什么时候被调用。

```text
* 推送消息存在四种情况：
*  ①消息推送到server，但是在server里找不到交换机
*      结论： ①这种情况触发的是 ConfirmCallback 回调函数。
*  ②消息推送到server，找到交换机了，但是没找到队列
*      结论：②这种情况触发的是 ConfirmCallback和RetrunCallback两个回调函数。
*  ③消息推送到sever，交换机和队列啥都没找到
*      结论： ③这种情况触发的是 ConfirmCallback 回调函数。
*  ④消息推送成功
*      结论： ④这种情况触发的是 ConfirmCallback 回调函数。
*
*   总结： RetrunCallback只有在推送到交换机正常，但是推送到队列失败的情况下才会触发。
*          而 ConfirmCallback 主要是在推送到交换机的失败的时候触发的。要注意的是其实推送成功到交换机也是会触发。
*
*   在来仔细看看这个RabbitTemplate.ConfirmCallback的函数式接口。中间那个ack可以用来分辨是成功的回调还是失败的回调。
*   true为成功，false为失败。
*
*   =====
*   到此为止都是将消息投递到队列的情况。那么，从队列里面消费消息有没有什么回调函数呢？
*   和生产者的消息确认机制不同，因为消息接收本来就是在监听消息，符合条件的消息就会消费下来。
*   所以，消息接收的确认机制主要存在三种模式：
*
*   1. 自动确认。当RabbitMQ成功将消息发出（即将消息成功写入TCP Socket）中立即认为本次投递已经被正确处理，不管消费者端是否成功处理本次投递。
*   所以这种情况如果消费端消费逻辑抛出异常，也就是消费端没有处理成功这条消息，那么就相当于丢失了消息。
*   2.条件确认
*   3. 手动确认。（推荐）
*   https://www.jianshu.com/p/537cb84ba72f
```

在生产端，通过不同的交换机策略。将交换机绑定到队列上，并且给予一个routeing key。然后在发送消息的时候，发送的消息会带上routeing key 以及要发送给哪个交换机。那么在将消息发送给交换机之后，rabbitmq会根据这个交换机的策略（到底是direct，或者是fanout ... ）来决定发给哪个队列。

打个比方。direct的策略就会精确匹配消息带上的routeing key和与交换机绑定的队列的routeing key。只有当两者完全匹配了之后，才会发送给相应的队列。发送给相应的队列之后的逻辑就比较简单了。发送队列成功后，剩下的就是消费了。

https://blog.csdn.net/qq_35387940/article/details/100514134?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control

### 如何保证消息的可靠性

https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md

首先，消息可能会弄丢的阶段会有两个。就比如说生产者在将消息发送给rabbitmq的过程中丢失了（因为网络原因之类的），这是一个部分。还有可能就是在rabbitmq中，rabbitmq给消息弄丢了。对于这两种情况都有不同的解决方案。

第一个过程：

一般来说有两种解决方案。一个就是开启rabbitmq的事务机制。如果发生了错误，那么发送端可以回滚消息。

```java
// 开启事务
channel.txSelect
try {
    // 这里发送消息
} catch (Exception e) {
    channel.txRollback

    // 这里再次重发这条消息
}

// 提交事务
channel.txCommit
```

但是问题是，RabbitMQ 事务机制（同步）一搞，基本上**吞吐量会下来，因为太耗性能**。所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

事务机制和 `confirm` 机制最大的不同在于，**事务机制是同步的**，你提交一个事务之后会**阻塞**在那儿，但是 `confirm` 机制是**异步**的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。

所以一般在生产者这块**避免数据丢失**，都是用 `confirm` 机制的。

### kafka

启动命令

```
bin\windows\kafka-server-start.bat config\server.properties
```

消费命令

```
bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic demo --from-beginning
```

消费者

![kafka消费者](../../TyporaImages/kafka消费者.png)

### Kafka线上集群怎么部署

 Kafka 客户端底层使用了 Java的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是 select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的I/O 性能。

针对存储信息的重要参数有以下这么几个：

log.dirs：这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。在线上生产环境中一定要为log.dirs配置多个路径。

### Kafka 会不会丢消息？怎么处理的?

https://zhuanlan.zhihu.com/p/354772550

1. 首先，可能在broker中丢失消息。因为消息一开始是存在broker机器中的pagecache中的。那么，此时机器宕机，内存中的数据还没来得及保存到磁盘上面，于是就造成了数据的丢失。此时可以配置acks来提高数据的可靠性，但是高可靠性以为这效率低下，这是有两面性的 。

### 第一章  初始kafka

> kafka所扮演的三大角色

- 消息系统

  通用消息中间件的功能。而且还提供了消息顺序性保障和回溯消费的功能。

- 存储系统 

  因为kafka是将消息消息持久化到磁盘上面的，而且又有多副本的机制。所以可以把kafka当做长期存放数据的数据存储系统来使用。

- 流式处理平台

> kakfa中的一些术语

- producer

  生产者。

- topic

  主题。每一条消息都属于一个主题。

- partition

  分区。我们可以通过增加分区数，来实现水平拓展。就是说减少一个机器的压力。不同的分区可以在不同的机器上。

- replica

  副本。通过多副本的机制提高容灾能力。

- AR

  AR = ISR + OSR

- ISR

  与leader保持同步的分区。当然，leader也属于ISR。

- OSR

  未及时与leader同步消息的分区。

- HW

  高水位。就是所有leader和follower中LEO的最小值。消费者只能消费这个值之前的消息。这样保证的消息可靠性。

- LEO

  leo就是当前消息要写入的分区的位置。就是最后一个写入成功的消息的offset的后一个位置。

> 服务端参数配置

- log.dir / log.dirs

  这两个用来配置消息保存到磁盘的哪个位置。log.dirs优先级比较高。

- broker.id 

  broker.id 是在启动的时候必须要配置的一个参数。每个broker都有一个唯一的id。那么这个id的生成方式有两种：

  第一种是在配置文件`server/server.properties`中配置了。那么就使用这个。而且默认值为-1，但是broker.id必须要大于0的值。

  第二种是自动生成。kafka提供了两个broker端的参数`broker.id.generation.enable`和`reserved.broker.max.id`来配合生成新的brokerid。`reserved.broker.max.id`是基准值，就是说生成的brokerid必须要大于这个值。默认值为1000.那么生成的原理就是利用zk中一个节点的版本号来生成的。zk中的节点每被修改一次，该节点的version自段就会自增1.那么就相当于一个发号器，那么这个version加上`reserved.broker.max.id`就是brokerID。

  还有一个地方会存放brokerID，那就是meta.properties文件中。这个文件中的值是在后续写入的。比如说自动生成后，就写入。这个文件所在目录就是log.dirs中配置的日志根目录下。而且，如果这个文件中的brokerID和`server/server.properties`中的不同，还会抛出异常。

### 第二章 生产者

> ProducerRecord 对象

这个对象是生产者创建出来的。消息的主题就放在里面。

```java
public class ProducerRecord<K, V> {
    private final String topic; 
    private final Integer partition;
    private final Headers headers;
    private final K key;
    private final V value;
    private final Long timestamp;
  .....
```

- key的作用

1. key就是消息的键。这个键的作用可以用来作为消息的附加信息。

2. 还可以用来计算消息将会被发送到哪个分区中。

   为啥有partition指定分区了还需要这个key来计算呢。原因就是当partition没有指定的时候，就会通过key来计算。计算方式是通过分区器来计算的。默认的分区器是将key通过hash函数得到值，在根据这个值来计算分区。那么可能会将它发送到一个不可用的分区中。也可以自定义分区器。只需要实现Partioner接口即可。然后在生产者中配置一下。

3. 日志压缩功能

   有key的消息可以支持日志压缩。就是将key相同的消息只保留最后一份。有点像Redis的RDB。有一个后台线程来清理污浊率最高的日志。这个线程首先会建立一张hash表。key是key的hash值，然后value是消息最后一条记录的offset。就是说，这个hash表保存了ProducerRecord中的key的hash和该ProducerRecord的偏移量。但是是最后一条的。然后该线程再遍历一次，将不是最后一条的消息给删除了。

> 消息的发送

一共有三种发送方式：

1. 发后就忘 fire-and-forget

    只是单纯的调用send()方法进行发送。

2. 同步 sync

   通过返回值为future对象。来调用future的get()方法来阻塞。直到得到结果。那么，在发送的过程中会出现两类异常，可以重试异常和不可重试异常。对于可重试异常，可以设置retries来设置重试次数。在重试次数过后，就会抛出异常。

3. 异步 asyhc

   一般做法是设置一个回调函数。